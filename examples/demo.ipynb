{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import abmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beplerberger loaded to cpu\n",
      "Loaded the Pre-trained Model!\n",
      "beplerberger loaded to cpu\n",
      "Loaded the Pre-trained Model!\n"
     ]
    }
   ],
   "source": [
    "# Load AbMAP \n",
    "# Using Bepler-Berger as foundational model\n",
    "abmap_H = abmap.load_abmap(pretrained_path='../pretrained_models/AbMAP_beplerberger_H.pt', plm_name='beplerberger')\n",
    "abmap_L = abmap.load_abmap(pretrained_path='../pretrained_models/AbMAP_beplerberger_L.pt', plm_name='beplerberger')\n",
    "\n",
    "# Using ESM1b\n",
    "# abmap_H = abmap.load_abmap(pretrained_path='../pretrained_models/AbMAP_esm1b_H.pt', plm_name='esm1b')\n",
    "# abmap_L = abmap.load_abmap(pretrained_path='../pretrained_models/AbMAP_esm1b_L.pt', plm_name='esm1b')\n",
    "\n",
    "# Using ESM2\n",
    "# abmap_H = abmap.load_abmap(pretrained_path='../pretrained_models/AbMAP_esm2_H.pt', plm_name='esm2')\n",
    "# abmap_L = abmap.load_abmap(pretrained_path='../pretrained_models/AbMAP_esm2_L.pt', plm_name='esm2')\n",
    "\n",
    "# Using ProtBert\n",
    "# abmap_H = abmap.load_abmap(pretrained_path='../pretrained_models/AbMAP_protbert_H.pt', plm_name='protbert')\n",
    "# abmap_L = abmap.load_abmap(pretrained_path='../pretrained_models/AbMAP_protbert_L.pt', plm_name='protbert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/anarci_files/temp0\n",
      "Sequence: EVQLVESGGGLVQPGGSLRLSCAASGFTFSSYWMHWVRQAPGKGLVWVSRINSDGSSTSYADSVKGRFTISRDNAKNTLYLQMNSLRAEDTAVYYCAGSYRSLFDYWGQGTLVTVSS\n",
      "scheme: chothia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Non IG chains cannot be numbered with the chothia scheme. These will be ignored.\n",
      "Error:  b'\\nError: File existence/permissions problem in trying to open HMM file /Users/I0479386/opt/anaconda3/envs/abmap_main/lib/python3.9/site-packages/anarci/dat/HMMs/ALL.hmm.\\nHMM file /Users/I0479386/opt/anaconda3/envs/abmap_main/lib/python3.9/site-packages/anarci/dat/HMMs/ALL.hmm not found (nor an .h\\n\\n'\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39m# Contrastive augmentation (PLM, mutagenesis, CDR focus)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m x \u001b[39m=\u001b[39m abmap\u001b[39m.\u001b[39mProteinEmbedding(demo_seq, chain_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mH\u001b[39m\u001b[39m'\u001b[39m, embed_device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m----> 6\u001b[0m x\u001b[39m.\u001b[39;49mcreate_cdr_specific_embedding(embed_type\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mbeplerberger\u001b[39;49m\u001b[39m'\u001b[39;49m, k\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n\u001b[1;32m      8\u001b[0m \u001b[39m# # Pass the augmented embedding to AbMAP to get final embedding\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/abmap_main/lib/python3.9/site-packages/abmap/abmap_augment.py:217\u001b[0m, in \u001b[0;36mProteinEmbedding.create_cdr_specific_embedding\u001b[0;34m(self, embed_type, k, separator, mask)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[39mCreate a CDR-specific embedding directly from sequence\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[39membed_type : embed with which general purpose PLM? (i.e. beplerberger)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[39mmask : Appending a mask that indicates which CDR a residue belongs to (1, 2, 3) (default: True)\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_seq(embed_type \u001b[39m=\u001b[39m embed_type)\n\u001b[0;32m--> 217\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_cdr_mask()\n\u001b[1;32m    219\u001b[0m kmut_matr_h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_kmut_matrix(num_muts\u001b[39m=\u001b[39mk, embed_type\u001b[39m=\u001b[39membed_type)\n\u001b[1;32m    220\u001b[0m cdr_embed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_cdr_embedding(kmut_matr_h, sep \u001b[39m=\u001b[39m separator, mask \u001b[39m=\u001b[39m mask)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/abmap_main/lib/python3.9/site-packages/abmap/abmap_augment.py:42\u001b[0m, in \u001b[0;36mProteinEmbedding.create_cdr_mask\u001b[0;34m(self, scheme, buffer_region)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_cdr_mask\u001b[39m(\u001b[39mself\u001b[39m, scheme\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mchothia\u001b[39m\u001b[39m'\u001b[39m, buffer_region \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcdr_mask \u001b[39m=\u001b[39m get_boolean_mask(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchain_type, scheme, buffer_region, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdev, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfold)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/abmap_main/lib/python3.9/site-packages/abmap/utils.py:96\u001b[0m, in \u001b[0;36mget_boolean_mask\u001b[0;34m(sequence, chain_type, scheme, buffer_region, dev, fold, anarci_dir)\u001b[0m\n\u001b[1;32m     94\u001b[0m regions \u001b[39m=\u001b[39m all_regions[chain_type]\n\u001b[1;32m     95\u001b[0m \u001b[39mif\u001b[39;00m chain_type \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mH\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 96\u001b[0m     file_name \u001b[39m=\u001b[39m glob\u001b[39m.\u001b[39;49mglob(anarci_dir\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m_H.csv\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(dev))[\u001b[39m0\u001b[39;49m]\n\u001b[1;32m     97\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     98\u001b[0m     file_name \u001b[39m=\u001b[39m glob\u001b[39m.\u001b[39mglob(anarci_dir\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_KL.csv\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(dev))[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Get embedding for one sequence\n",
    "demo_seq = 'EVQLVESGGGLVQPGGSLRLSCAASGFTFSSYWMHWVRQAPGKGLVWVSRINSDGSSTSYADSVKGRFTISRDNAKNTLYLQMNSLRAEDTAVYYCAGSYRSLFDYWGQGTLVTVSS'\n",
    "\n",
    "# Contrastive augmentation (PLM, mutagenesis, CDR focus)\n",
    "x = abmap.ProteinEmbedding(demo_seq, chain_type='H', embed_device=torch.device('cpu'))\n",
    "x.create_cdr_specific_embedding(embed_type='beplerberger', k=50)\n",
    "\n",
    "# # Pass the augmented embedding to AbMAP to get final embedding\n",
    "with torch.no_grad():\n",
    "    embed_var = abmap_H.embed(x.cdr_embedding.unsqueeze(0), embed_type='variable') # residue-level embeddings\n",
    "    embed_fl = abmap_H.embed(x.cdr_embedding.unsqueeze(0), embed_type='fixed') # fixed-length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embed_var' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m embed_var\u001b[39m.\u001b[39mshape, embed_fl\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embed_var' is not defined"
     ]
    }
   ],
   "source": [
    "embed_var.shape, embed_fl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings for a fasta file of sequences\n",
    "# COMING VERY SOON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ESM2 as foundational model\n",
    "# COMING SOON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning AbMAP on your own functional data\n",
    "# COMING SOON"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec653636a9367c33a965d45a184026a891063ec85ff6820adf4646f7775bee26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
