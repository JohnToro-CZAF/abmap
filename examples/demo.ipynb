{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Demo and Tutorial</u> \n",
    "Welcome to our demo and tutorial! This will be continually updated with more examples and use cases. Make sure abmap and ANARCI are installed before running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import abmap"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <u>Foundational Models</u>\n",
    "**AbMAP** leverages foundational protein language models (PLMs) like ESM2 to embed antibody sequences into a continuous embedding space. We've pre-trained several models using the outputs of these foundational models, which can be easily loaded and used for downstream tasks (e.g. property pred, structure pred, etc.). These are not \"fine-tuned\" versions of ESM2, but rather models that have been trained on the outputs of ESM2.\n",
    "\n",
    "We've included pre-trained models from the outputs of four different foundational models (ESM2, ESM1b, Bepler-Berger, and ProtBERT). For each model, we have two checkpoints: one trained on heavy chain (VH) antibody sequences from SabDAB and the other chained on light chain (VL) sequences. You can load them here. We'd recommend running this notebook with GPU capability for faster inference, but it's not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beplerberger loaded to cpu\n",
      "Loaded the Pre-trained Model!\n",
      "beplerberger loaded to cpu\n",
      "Loaded the Pre-trained Model!\n"
     ]
    }
   ],
   "source": [
    "# -------- Load AbMAP \n",
    "# Using Bepler-Berger as foundational model (best for structure prediction)\n",
    "abmap_H = abmap.load_abmap(pretrained_path='../pretrained_models/AbMAP_beplerberger_H.pt', plm_name='beplerberger')\n",
    "abmap_L = abmap.load_abmap(pretrained_path='../pretrained_models/AbMAP_beplerberger_L.pt', plm_name='beplerberger')\n",
    "\n",
    "# Using ESM2 (best for functional prediction, e.g. affinity, paratope prediction, etc.)\n",
    "# abmap_H = abmap.load_abmap(pretrained_path='../pretrained_models/AbMAP_esm2_H.pt', plm_name='esm2')\n",
    "# abmap_L = abmap.load_abmap(pretrained_path='../pretrained_models/AbMAP_esm2_L.pt', plm_name='esm2')\n",
    "\n",
    "# Using ESM1b\n",
    "# abmap_H = abmap.load_abmap(pretrained_path='../pretrained_models/AbMAP_esm1b_H.pt', plm_name='esm1b')\n",
    "# abmap_L = abmap.load_abmap(pretrained_path='../pretrained_models/AbMAP_esm1b_L.pt', plm_name='esm1b')\n",
    "\n",
    "# Using ProtBert\n",
    "# abmap_H = abmap.load_abmap(pretrained_path='../pretrained_models/AbMAP_protbert_H.pt', plm_name='protbert')\n",
    "# abmap_L = abmap.load_abmap(pretrained_path='../pretrained_models/AbMAP_protbert_L.pt', plm_name='protbert')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <u>AbMAP embedding process</u>\n",
    "Embedding a sequence with AbMAP occurs in 3 steps:\n",
    "1. Get the embedding from a **foundational PLM**\n",
    "2. **Augment** the embedding to focus on CDRs, the regions most important for binding and function\n",
    "3. **Enhance** the embedding with knowledge of antibody structure and function\n",
    "4. **Fine-tune** on other functional properties of interest (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Non IG chains cannot be numbered with the chothia scheme. These will be ignored.\n"
     ]
    }
   ],
   "source": [
    "# ----- Get embedding for one sequence (steps 1-3)\n",
    "demo_seq = 'EVQLVESGGGLVQPGGSLRLSCAASGFTFSSYWMHWVRQAPGKGLVWVSRINSDGSSTSYADSVKGRFTISRDNAKNTLYLQMNSLRAEDTAVYYCAGSYRSLFDYWGQGTLVTVSS'\n",
    "\n",
    "# Contrastive augmentation (PLM, mutagenesis, CDR focus)\n",
    "x = abmap.ProteinEmbedding(demo_seq, chain_type='H', embed_device=torch.device('cpu')) # push sequence through foundational model\n",
    "x.create_cdr_specific_embedding(embed_type='beplerberger', k=20) # decrease k to speed up, would recommend k >= 6\n",
    "\n",
    "# # Pass the augmented embedding to AbMAP to get final embedding\n",
    "with torch.no_grad():\n",
    "    embed_var = abmap_H.embed(x.cdr_embedding.unsqueeze(0), embed_type='variable') # residue-level embeddings\n",
    "    embed_fl = abmap_H.embed(x.cdr_embedding.unsqueeze(0), embed_type='fixed') # fixed-length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 31, 256]), torch.Size([1, 512]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variable-length CDR-only embedding and fixed-length embedding\n",
    "embed_var.shape, embed_fl.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <u>Embed a whole fasta file</u>\n",
    "We've also made it easy to create embeddings for sequences in a fasta file. The embeddings will be stored in a directory for later use. These AbMAP embeddings can be thought of as features to train an additional model on more tasks. They can also be used to compare sequences in a continuous embedding space if you, for example, would like to cluster sequences by structural & functional similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beplerberger loaded to cpu\n",
      "[2023-05-18-15:09:58] # Storing to ../data/test_embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 6456.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# -------- Get embeddings for a fasta file of sequences\n",
    "fasta_path = '../data/test.fasta'\n",
    "output_path = '../data/test_embeddings'\n",
    "\n",
    "# outputs saved to output_path directory\n",
    "abmap.augment_from_fasta(fastaPath=fasta_path,\n",
    "                                           outputPath=output_path,\n",
    "                                        chain_type='H', \n",
    "                                        embed_type='beplerberger',\n",
    "                                        num_mutations=10,\n",
    "                                        device='cpu') # change to 0 if using 'cuda'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <u>Fine-tuning AbMAP on your own functional data</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Fine-tuning functional data (step 4)\n",
    "'''Create dataloader for your data, see abmap/dataloader.py for examples. \n",
    "This dataloader should take in your embeddings (stored in a directory now) and your functional labels.'''\n",
    "\n",
    "# Define a model, see abmap.models.py for examples\n",
    "model = abmap.PropertyPredictorAttn()\n",
    "\n",
    "# TODO - train model with PytorchLightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec653636a9367c33a965d45a184026a891063ec85ff6820adf4646f7775bee26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
